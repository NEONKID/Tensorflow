{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[ 0.58771551  0.08172726]] [ 0.19289613]\n",
      "20 [[ 0.20054734  0.21774523]] [ 0.23305038]\n",
      "40 [[ 0.12895437  0.21611501]] [ 0.27487135]\n",
      "60 [[ 0.10969249  0.20719562]] [ 0.29063094]\n",
      "80 [[ 0.10346626  0.20282689]] [ 0.29651463]\n",
      "100 [[ 0.10127083  0.20106983]] [ 0.29870442]\n",
      "120 [[ 0.10047003  0.20039999]] [ 0.29951853]\n",
      "140 [[ 0.10017436  0.20014894]] [ 0.29982111]\n",
      "160 [[ 0.10006475  0.20005539]] [ 0.29993349]\n",
      "180 [[ 0.10002407  0.20002061]] [ 0.29997528]\n",
      "200 [[ 0.10000893  0.20000766]] [ 0.2999908]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "\n",
    "'''\n",
    "이 코드는 GradientDescent를 사용하여 인자를 찾아내는 코드이다.\n",
    "무슨 말인지 처음에는 잘 모를 수도 있으니 코드를 보며 습득해보자.\n",
    "\n",
    "이 코드를 보기 전에, 경사하강법 알고리즘을 습득하고 있어야 한다.\n",
    "이 알고리즘은 1차 근사값을 찾기 위해 기울기를 계속 낮은 쪽으로 이동시키는\n",
    "반복 알고리즘이다.\n",
    "\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "프로그램 준비 \n",
    "'''\n",
    "\n",
    "# numpy를 이용해 100개의 연습 데이터를 생성한다. (float64 --> float32)\n",
    "x_data = np.float32(np.random.rand(2,100))\n",
    "\n",
    "# LinearRegression 처럼 학습 값은 아래의 식으로...\n",
    "y_data = np.dot([0.100, 0.200], x_data) + 0.300\n",
    "\n",
    "# b는 당연하 듯 0으로 초기화\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# W는 1x2 형태의 Weight 변수.. (균등 랜덤값으로 초기화)\n",
    "W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))\n",
    "y = tf.matmul(W, x_data) + b\n",
    "\n",
    "# 손실 함수 정의,,\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "\n",
    "# 경사하강법으로 손실 함수 최소화,, (법칙임)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5) # 여기서 0.5는 학습 비율,,\n",
    "\n",
    "# 학습 Operation 정의\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "'''\n",
    "프로그램 실행\n",
    "'''\n",
    "\n",
    "# 모든 변수 초기화,,\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# 세션 시작,,\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 200번 학습하도록 수행,,\n",
    "for step in xrange(0, 201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0: # 20개씩 짜름,,\n",
    "        print step, sess.run(W), sess.run(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
